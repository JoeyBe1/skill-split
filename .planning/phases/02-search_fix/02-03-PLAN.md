---
phase: 02-search_fix
plan: 03
type: fix
wave: 2
depends_on: ["02-01", "02-02"]
files_modified:
  - core/database.py
  - test/test_database.py
autonomous: true

must_haves:
  truths:
    - "FTS5 index stays synchronized when sections are deleted via CASCADE"
    - "No orphaned FTS5 entries after section deletion"
    - "FTS5 sync happens automatically in all CRUD operations"
    - "Tests verify FTS integrity after insert/update/delete operations"
  artifacts:
    - path: "core/database.py"
      provides: "Explicit FTS5 synchronization in all section CRUD operations"
      contains: "_sync_section_fts|INSERT OR REPLACE|DELETE"
      min_lines: 50
    - path: "test/test_database.py"
      provides: "Tests for FTS5 synchronization after CRUD operations"
      contains: "test_fts_sync|test_cascade_delete"
      min_lines: 60
  key_links:
    - from: "core/database.py::_store_sections"
      to: "sections_fts FTS5 table"
      via: "INSERT OR REPLACE ensures FTS index sync"
      pattern: "sections_fts.*INSERT"
    - from: "core/database.py::delete_file (CASCADE)"
      to: "sections_fts cleanup"
      via: "CASCADE deletes should trigger FTS cleanup"
      pattern: "CASCADE|DELETE.*sections"
---

<objective>
Fix FTS5 index synchronization to prevent orphaned entries and ensure search integrity after CRUD operations.

Purpose: FTS5 external content table requires proper synchronization. Current implementation uses INSERT OR REPLACE which handles most cases, but CASCADE deletes may leave orphaned FTS entries. Explicit sync on all CRUD operations ensures index integrity.

Output: FTS5 index always synchronized, no orphaned entries, tests verify integrity after all operations.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/research/search-investigation.md
@.planning/phases/02-search_fix/02-01-PLAN.md
@.planning/phases/02-search_fix/02-02-PLAN.md

@core/database.py
@test/test_database.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add explicit FTS5 sync helper method</name>
  <files>core/database.py</files>
  <action>
    Add helper method for explicit FTS5 synchronization.

    Add after _sync_section_fts method:

    ```python
    def _ensure_fts_sync(self, conn: sqlite3.Connection) -> None:
        """
        Ensure FTS5 index is synchronized with main sections table.

        FTS5 external content tables can become out of sync during bulk
        operations or CASCADE deletes. This forces an explicit sync.

        Args:
            conn: Active database connection
        """
        try:
            # FTS5 'optimize' command rebuilds index ensuring sync
            conn.execute("INSERT INTO sections_fts(sections_fts) VALUES('optimize')")
        except Exception:
            # Optimize may fail if index is empty, ignore
            pass

    def _sync_single_section_fts(self, conn: sqlite3.Connection, section_id: int) -> None:
        """
        Synchronize a single section's FTS5 entry.

        Ensures FTS index contains current section data after updates.

        Args:
            conn: Active database connection
            section_id: Section ID to synchronize
        """
        # FTS5 external content auto-syncs on INSERT/UPDATE
        # This ensures explicit sync after potential issues
        conn.execute(
            """
            INSERT INTO sections_fts(rowid, title, content)
            SELECT id, title, content
            FROM sections
            WHERE id = ?
            ON CONFLICT(rowid) DO UPDATE SET
                title = excluded.title,
                content = excluded.content
            """,
            (section_id,)
        )
    ```

    Why: Provides explicit sync methods for FTS5 index, handles edge cases where auto-sync may fail.
  </action>
  <verify>
    Run: `python -c "from core.database import DatabaseStore; import sqlite3; db = DatabaseStore(':memory:'); print(hasattr(db, '_ensure_fts_sync'))"`
    Expected: True
  </verify>
  <done>_ensure_fts_sync() and _sync_single_section_fts() methods added.</done>
</task>

<task type="auto">
  <name>Task 2: Update _store_sections to ensure FTS sync</name>
  <files>core/database.py</files>
  <action>
    Modify _store_sections to call explicit FTS sync after bulk operations.

    Find the _store_sections method and add sync call after section insertion:

    ```python
    def _store_sections(
        self,
        conn: sqlite3.Connection,
        file_id: int,
        sections: List[Section],
        parent_id: Optional[int] = None,
        order_start: int = 0
    ) -> int:
        """
        Store sections in database with FTS5 synchronization.

        ... existing docstring ...
        """
        order_index = order_start

        for section in sections:
            # Insert section
            cursor = conn.execute(
                """
                INSERT INTO sections (
                    file_id, parent_id, level, title, content,
                    line_start, line_end, order_index, closing_tag_prefix
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                (
                    file_id, parent_id, section.level, section.title,
                    section.content, section.line_start, section.line_end,
                    order_index, section.closing_tag_prefix
                )
            )

            section_id = cursor.lastrowid

            # Recursive: store children
            if section.children:
                self._store_sections(
                    conn, file_id, section.children, section_id, order_index
                )

            order_index += 1

        # ENSURE FTS SYNC after bulk insert
        # This guarantees FTS index is up-to-date for new sections
        self._ensure_fts_sync(conn)

        return order_index - order_start
    ```

    Also update store_file to call sync after complete file storage:

    ```python
    def store_file(
        self,
        path: str,
        document: ParsedDocument,
        file_hash: str
    ) -> int:
        """
        Store a parsed file with metadata and sections.

        ... existing docstring ...
        """
        with sqlite3.connect(self.db_path) as conn:
            # ... existing file insert/update logic ...

            # Store sections (already includes FTS sync)
            section_count = self._store_sections(
                conn, file_id, document.sections
            )

            # FINAL FTS SYNC to ensure complete index
            self._ensure_fts_sync(conn)

            return file_id
    ```

    Why: Ensures FTS5 index synchronized after all section storage operations, prevents orphaned entries.
  </action>
  <verify>
    Run: `python -m pytest test/test_database.py::TestStoreAndRetrieve::test_store_and_retrieve_file -v`
    Expected: Test passes, FTS index contains new sections
  </verify>
  <done>_store_sections() and store_file() call _ensure_fts_sync() after operations.</done>
</task>

<task type="auto">
  <name>Task 3: Add FTS cleanup to delete operations</name>
  <files>core/database.py</files>
  <action>
    Ensure CASCADE delete triggers FTS cleanup.

    Add explicit method to verify FTS cleanup after delete:

    ```python
    def delete_file(self, file_id: int) -> bool:
        """
        Delete a file and all its sections with FTS cleanup.

        CASCADE delete should remove sections, but we explicitly
        verify FTS index cleanup.

        Args:
            file_id: File ID to delete

        Returns:
            True if deleted, False if not found
        """
        with sqlite3.connect(self.db_path) as conn:
            # Check file exists
            cursor = conn.execute("SELECT id FROM files WHERE id = ?", (file_id,))
            if not cursor.fetchone():
                return False

            # Delete file (CASCADE deletes sections)
            conn.execute("DELETE FROM files WHERE id = ?", (file_id,))

            # Explicit FTS sync after CASCADE
            # Removes any orphaned FTS entries
            self._ensure_fts_sync(conn)

            # Verify no orphaned FTS entries remain
            cursor = conn.execute(
                """
                SELECT COUNT(*) FROM sections_fts
                WHERE rowid NOT IN (SELECT id FROM sections)
                """
            )
            orphaned = cursor.fetchone()[0]

            if orphaned > 0:
                # Clean up orphans explicitly
                conn.execute(
                    """
                    DELETE FROM sections_fts
                    WHERE rowid NOT IN (SELECT id FROM sections)
                    """
                )

            conn.commit()
            return True
    ```

    Why: CASCADE deletes sections but FTS external content may leave orphans, explicit cleanup ensures index integrity.
  </action>
  <verify>
    Run: `python -c "from core.database import DatabaseStore; from models import ParsedDocument, Section, FileType; db = DatabaseStore(':memory:'); doc = ParsedDocument(FileType.MARKDOWN, '', [Section(1, 'Test', 'Content', 1, 2)], '', FileType.MARKDOWN, ''); fid = db.store_file('/test', doc, 'hash'); result = db.delete_file(fid); print(f'Deleted: {result}')"`
    Expected: Deleted: True, no orphaned FTS entries
  </verify>
  <done>delete_file() includes explicit FTS cleanup and orphan verification.</done>
</task>

<task type="auto">
  <name>Task 4: Add comprehensive FTS sync tests</name>
  <files>test/test_database.py</files>
  <action>
    Add tests verifying FTS5 synchronization after all operations.

    ```python
    class TestFTS5Synchronization:
        """Test FTS5 index synchronization with CRUD operations."""

        def test_fts_sync_after_insert(self, db_store):
            """FTS index contains newly inserted sections."""
            from models import ParsedDocument, Section, FileType

            doc = ParsedDocument(
                file_type=FileType.MARKDOWN,
                frontmatter="",
                sections=[Section(level=1, title="FTS Test", content="Searchable content", line_start=1, line_end=2)]
            )
            file_id = db_store.store_file("/test/fts_insert.md", doc, "hash")

            # Search should find the new section
            results = db_store.search_sections_with_rank("fts test")

            assert len(results) > 0, "FTS index should contain new section"

        def test_fts_sync_after_update(self, db_store):
            """FTS index reflects updated section content."""
            from models import ParsedDocument, Section, FileType

            # Insert original
            doc = ParsedDocument(
                file_type=FileType.MARKDOWN,
                frontmatter="",
                sections=[Section(level=1, title="Original", content="Original content", line_start=1, line_end=2)]
            )
            file_id = db_store.store_file("/test/fts_update.md", doc, "hash1")

            # Update with new content
            doc2 = ParsedDocument(
                file_type=FileType.MARKDOWN,
                frontmatter="",
                sections=[Section(level=1, title="Updated", content="Updated searchable text", line_start=1, line_end=2)]
            )
            db_store.store_file("/test/fts_update.md", doc2, "hash2")

            # Search for new content
            results = db_store.search_sections_with_rank("updated searchable")

            assert len(results) > 0, "FTS index should reflect updated content"

        def test_fts_cleanup_after_delete(self, db_store):
            """Deleting file removes FTS entries (no orphans)."""
            from models import ParsedDocument, Section, FileType

            # Insert file
            doc = ParsedDocument(
                file_type=FileType.MARKDOWN,
                frontmatter="",
                sections=[
                    Section(level=1, title="Delete Test", content="To be deleted", line_start=1, line_end=2),
                    Section(level=2, title="Child", content="Also deleted", line_start=3, line_end=4),
                ]
            )
            file_id = db_store.store_file("/test/fts_delete.md", doc, "hash")

            # Verify FTS has entries
            results_before = db_store.search_sections_with_rank("delete test")
            assert len(results_before) > 0

            # Delete file
            result = db_store.delete_file(file_id)
            assert result is True

            # Search should find nothing
            results_after = db_store.search_sections_with_rank("delete test")
            assert len(results_after) == 0, "FTS entries should be removed after delete"

        def test_no_orphaned_fts_entries(self, db_store):
            """No orphaned FTS entries after operations."""
            from models import ParsedDocument, Section, FileType
            import sqlite3

            # Insert and delete multiple files
            for i in range(5):
                doc = ParsedDocument(
                    file_type=FileType.MARKDOWN,
                    frontmatter="",
                    sections=[Section(level=1, title=f"Test {i}", content=f"Content {i}", line_start=1, line_end=2)]
                )
                file_id = db_store.store_file(f"/test/orphan_{i}.md", doc, f"hash{i}")
                db_store.delete_file(file_id)

            # Check for orphans
            with sqlite3.connect(db_store.db_path) as conn:
                cursor = conn.execute(
                    """
                    SELECT COUNT(*) FROM sections_fts
                    WHERE rowid NOT IN (SELECT id FROM sections)
                    """
                )
                orphaned = cursor.fetchone()[0]

            assert orphaned == 0, f"Should have no orphaned FTS entries, found {orphaned}"

        def test_fts_sync_after_cascade_delete(self, db_store):
            """CASCADE delete of sections triggers FTS cleanup."""
            from models import ParsedDocument, Section, FileType

            # Create file with nested sections
            doc = ParsedDocument(
                file_type=FileType.MARKDOWN,
                frontmatter="",
                sections=[
                    Section(
                        level=1, title="Parent", content="Parent content", line_start=1, line_end=4,
                        children=[
                            Section(level=2, title="Child 1", content="Child 1 content", line_start=2, line_end=3),
                            Section(level=2, title="Child 2", content="Child 2 content", line_start=3, line_end=4),
                        ]
                    )
                ]
            )
            file_id = db_store.store_file("/test/cascade.md", doc, "hash")

            # Verify all sections searchable
            results = db_store.search_sections_with_rank("child")
            assert len(results) == 2

            # Delete file (CASCADE deletes all sections)
            db_store.delete_file(file_id)

            # No sections should be found
            results = db_store.search_sections_with_rank("child")
            assert len(results) == 0

        def test_fts_integrity_after_bulk_operations(self, db_store):
            """FTS index remains consistent after bulk insert/delete."""
            from models import ParsedDocument, Section, FileType
            import sqlite3

            # Bulk insert 100 files
            file_ids = []
            for i in range(100):
                doc = ParsedDocument(
                    file_type=FileType.MARKDOWN,
                    frontmatter="",
                    sections=[Section(level=1, title=f"Bulk {i}", content=f"Content {i}", line_start=1, line_end=2)]
                )
                file_id = db_store.store_file(f"/test/bulk_{i}.md", doc, f"hash{i}")
                file_ids.append(file_id)

            # Verify FTS has all entries
            with sqlite3.connect(db_store.db_path) as conn:
                cursor = conn.execute("SELECT COUNT(*) FROM sections_fts")
                fts_count = cursor.fetchone()[0]

                cursor = conn.execute("SELECT COUNT(*) FROM sections")
                sections_count = cursor.fetchone()[0]

            assert fts_count == sections_count, "FTS count should match sections count"

            # Delete all files
            for file_id in file_ids:
                db_store.delete_file(file_id)

            # Verify both tables are empty
            with sqlite3.connect(db_store.db_path) as conn:
                cursor = conn.execute("SELECT COUNT(*) FROM sections_fts")
                fts_count = cursor.fetchone()[0]

                cursor = conn.execute("SELECT COUNT(*) FROM sections")
                sections_count = cursor.fetchone()[0]

            assert fts_count == 0
            assert sections_count == 0
    ```

    Why: Comprehensive tests verify FTS synchronization after insert, update, delete, cascade, and bulk operations.
  </action>
  <verify>
    Run: `python -m pytest test/test_database.py::TestFTS5Synchronization -v`
    Expected: All 6 tests pass
  </verify>
  <done>Tests verify FTS sync after insert, update, delete, cascade, bulk operations.</done>
</task>

</tasks>

<verification>
Overall verification:
1. Run all tests: `python -m pytest test/test_database.py -v`
   Expected: All tests pass, including 6 new FTS sync tests
2. Test FTS sync manually:
   ```python
   from core.database import DatabaseStore
   from models import ParsedDocument, Section, FileType
   db = DatabaseStore('test_sync.db')
   doc = ParsedDocument(FileType.MARKDOWN, '', [Section(1, 'Test', 'Content', 1, 2)], '', FileType.MARKDOWN, '')
   fid = db.store_file('/test', doc, 'hash')
   print(db.search_sections_with_rank('test'))
   db.delete_file(fid)
   print(db.search_sections_with_rank('test'))
   ```
   Expected: Finds section before delete, nothing after
3. Verify no orphans:
   ```python
   import sqlite3
   conn = sqlite3.connect('test_sync.db')
   c = conn.execute("SELECT COUNT(*) FROM sections_fts WHERE rowid NOT IN (SELECT id FROM sections)")
   print(c.fetchone()[0])
   ```
   Expected: 0
</verification>

<success_criteria>
1. FTS5 index synchronized after all section operations
2. No orphaned FTS entries after delete operations
3. CASCADE deletes properly clean up FTS index
4. Bulk operations maintain FTS integrity
5. All existing tests pass + 6 new FTS sync tests
6. Explicit sync methods added for edge cases
</success_criteria>

<output>
After completion, create `.planning/phases/02-search_fix/02-03-SUMMARY.md` with:
- FTS synchronization implementation details
- Test results for all sync scenarios
- Orphan detection and cleanup logic
- Performance impact (if any)
- Edge cases handled
</output>
