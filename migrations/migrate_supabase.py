#!/usr/bin/env python3
"""
Helper script to generate Supabase migration SQL commands for v1.0.0

This script generates SQL commands that you can run in your Supabase
SQL Editor to migrate your database to v1.0.0 schema.

Usage:
    python migrate_supabase.py              # Generate to stdout
    python migrate_supabase.py -o file.sql  # Save to file
"""

import argparse
import sys


def generate_migration_sql() -> str:
    """
    Generate SQL commands for Supabase migration to v1.0.0.

    Returns:
        SQL string to run in Supabase SQL Editor
    """
    return """-- ============================================
-- skill-split v1.0.0 Supabase Migration
-- Generated by migrate_supabase.py
--
-- Instructions:
-- 1. Login to Supabase: https://supabase.com/dashboard
-- 2. Select your project
-- 3. Go to SQL Editor
-- 4. Paste this entire script
-- 5. Click "Run" to execute
-- ============================================

-- Begin transaction for safety
BEGIN;

-- ============================================
-- Phase 1: Enable Extensions
-- ============================================

-- Enable pgvector for vector search support
CREATE EXTENSION IF NOT EXISTS vector;

-- ============================================
-- Phase 2: Update Sections Table
-- ============================================

-- Add missing columns for script handler support
ALTER TABLE sections
ADD COLUMN IF NOT EXISTS line_start INTEGER DEFAULT 0,
ADD COLUMN IF NOT EXISTS line_end INTEGER DEFAULT 0,
ADD COLUMN IF NOT EXISTS closing_tag_prefix TEXT DEFAULT '';

-- Update existing rows to have proper defaults
UPDATE sections
SET closing_tag_prefix = ''
WHERE closing_tag_prefix IS NULL;

UPDATE sections
SET line_start = 0
WHERE line_start IS NULL;

UPDATE sections
SET line_end = 0
WHERE line_end IS NULL;

-- ============================================
-- Phase 3: Create Performance Indexes
-- ============================================

-- Index for progressive disclosure queries
CREATE INDEX IF NOT EXISTS idx_sections_file_order
ON sections(file_id, parent_id, order_index);

-- Index for parent-child queries
CREATE INDEX IF NOT EXISTS idx_sections_file_parent
ON sections(file_id, parent_id);

-- Full-text search index (GIN)
CREATE INDEX IF NOT EXISTS idx_sections_search
ON sections USING gin(to_tsvector('english', title || ' ' || content));

-- ============================================
-- Phase 4: Update Files Table
-- ============================================

-- Add timestamp columns for audit trail
ALTER TABLE files
ADD COLUMN IF NOT EXISTS created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
ADD COLUMN IF NOT EXISTS updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW();

-- ============================================
-- Phase 5: Create Embeddings Table
-- ============================================

-- Table for storing vector embeddings
CREATE TABLE IF NOT EXISTS embeddings (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    section_id UUID NOT NULL REFERENCES sections(id) ON DELETE CASCADE,
    embedding vector(1536),
    model TEXT DEFAULT 'text-embedding-3-small',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Index for embedding lookups
CREATE INDEX IF NOT EXISTS idx_embeddings_section_id
ON embeddings(section_id);

-- Create HNSW index for fast vector similarity search
CREATE INDEX IF NOT EXISTS idx_embeddings_vector
ON embeddings USING hnsw(embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- ============================================
-- Phase 6: Update File Type Constraints
-- ============================================

-- Drop old constraint (if exists)
ALTER TABLE files DROP CONSTRAINT IF EXISTS files_type_check;

-- Add new constraint with all supported file types
ALTER TABLE files
ADD CONSTRAINT files_type_check
CHECK (type IN (
    'skill', 'command', 'reference', 'agent',
    'plugin', 'hook', 'output_style', 'config',
    'documentation', 'script'
));

-- ============================================
-- Phase 7: Create Auto-Update Trigger
-- ============================================

-- Function to auto-update updated_at timestamp
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Drop existing trigger if any
DROP TRIGGER IF EXISTS update_files_updated_at ON files;

-- Create trigger
CREATE TRIGGER update_files_updated_at
BEFORE UPDATE ON files
FOR EACH ROW
EXECUTE FUNCTION update_updated_at_column();

-- ============================================
-- Phase 8: Create Metadata Table (Optional)
-- ============================================

-- Table for storing schema version and other metadata
CREATE TABLE IF NOT EXISTS metadata (
    key TEXT PRIMARY KEY,
    value TEXT NOT NULL,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Insert current schema version
INSERT INTO metadata (key, value)
VALUES ('schema_version', '1.0.0')
ON CONFLICT (key) DO UPDATE
SET value = EXCLUDED.value,
    updated_at = NOW();

-- ============================================
-- Phase 9: Verification Queries
-- ============================================

-- These queries help verify the migration succeeded

-- Check sections table columns
-- SELECT column_name, data_type, column_default
-- FROM information_schema.columns
-- WHERE table_name = 'sections'
--   AND column_name IN ('line_start', 'line_end', 'closing_tag_prefix');

-- Check indexes were created
-- SELECT indexname, tablename
-- FROM pg_indexes
-- WHERE tablename IN ('sections', 'embeddings')
--   AND indexname LIKE 'idx_%';

-- Check file types constraint
-- SELECT pg_get_constraintdef(oid)
-- FROM pg_constraint
-- WHERE conname = 'files_type_check';

-- Check schema version
-- SELECT * FROM metadata WHERE key = 'schema_version';

-- ============================================
-- Commit Transaction
-- ============================================

COMMIT;

-- ============================================
-- Post-Migration Statistics
-- ============================================

-- Display success message
DO $$
BEGIN
    RAISE NOTICE '====================================';
    RAISE NOTICE 'Migration to v1.0.0 complete!';
    RAISE NOTICE '====================================';
    RAISE NOTICE 'Schema version: 1.0.0';
    RAISE NOTICE 'Extensions: vector (pgvector)';
    RAISE NOTICE 'New tables: embeddings, metadata';
    RAISE NOTICE 'New indexes: idx_sections_*, idx_embeddings_*';
    RAISE NOTICE '';
    RAISE NOTICE 'Next steps:';
    RAISE NOTICE '1. Verify: Run the verification queries above';
    RAISE NOTICE '2. Test: Ingest a test file';
    RAISE NOTICE '3. Monitor: Check performance with new indexes';
END $$;
"""


def generate_rollback_sql() -> str:
    """
    Generate SQL commands to rollback v1.0.0 migration.

    Returns:
        SQL string for rollback
    """
    return """-- ============================================
-- skill-split v1.0.0 Rollback Script
-- WARNING: This will revert the migration
-- ============================================

BEGIN;

-- Drop embeddings table
DROP TABLE IF EXISTS embeddings CASCADE;

-- Drop indexes
DROP INDEX IF EXISTS idx_sections_file_order;
DROP INDEX IF EXISTS idx_sections_file_parent;
DROP INDEX IF EXISTS idx_sections_search;
DROP INDEX IF EXISTS idx_embeddings_section_id;
DROP INDEX IF EXISTS idx_embeddings_vector;

-- Drop triggers and functions
DROP TRIGGER IF EXISTS update_files_updated_at ON files;
DROP FUNCTION IF EXISTS update_updated_at_column();

-- Drop new columns (PostgreSQL supports this)
ALTER TABLE sections
DROP COLUMN IF EXISTS closing_tag_prefix,
DROP COLUMN IF EXISTS line_start,
DROP COLUMN IF EXISTS line_end;

ALTER TABLE files
DROP COLUMN IF EXISTS created_at,
DROP COLUMN IF EXISTS updated_at;

-- Revert file type constraint
ALTER TABLE files DROP CONSTRAINT IF EXISTS files_type_check;

ALTER TABLE files
ADD CONSTRAINT files_type_check
CHECK (type IN ('skill', 'command', 'reference'));

-- Update metadata
DELETE FROM metadata WHERE key = 'schema_version';
INSERT INTO metadata (key, value) VALUES ('schema_version', '0.x');

COMMIT;

NOTICE 'Rollback complete. Database reverted to pre-v1.0.0 state.';
"""


def print_usage():
    """Print usage information."""
    print("Usage: python migrate_supabase.py [options]")
    print()
    print("Options:")
    print("  -o, --output FILE    Save SQL to file instead of stdout")
    print("  -r, --rollback       Generate rollback script instead")
    print("  --help               Show this help message")
    print()
    print("Examples:")
    print("  python migrate_supabase.py")
    print("  python migrate_supabase.py -o migration.sql")
    print("  python migrate_supabase.py -r -o rollback.sql")


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Generate Supabase migration SQL for skill-split v1.0.0",
        add_help=False
    )
    parser.add_argument(
        '-o', '--output',
        metavar='FILE',
        help='Save SQL to file'
    )
    parser.add_argument(
        '-r', '--rollback',
        action='store_true',
        help='Generate rollback script'
    )
    parser.add_argument(
        '--help',
        action='store_true',
        help='Show help message'
    )

    args = parser.parse_args()

    if args.help:
        print_usage()
        sys.exit(0)

    # Generate appropriate SQL
    if args.rollback:
        sql = generate_rollback_sql()
        default_filename = "supabase_rollback_v1.0.0.sql"
    else:
        sql = generate_migration_sql()
        default_filename = "supabase_migration_v1.0.0.sql"

    # Output SQL
    if args.output:
        try:
            with open(args.output, 'w') as f:
                f.write(sql)
            print(f"Generated: {args.output}")
            print()
            print("Next steps:")
            print("  1. Login to Supabase: https://supabase.com/dashboard")
            print("  2. Select your project")
            print("  3. Go to SQL Editor")
            print(f"  4. Open {args.output}")
            print("  5. Click 'Run' to execute")
        except Exception as e:
            print(f"Error writing file: {e}", file=sys.stderr)
            sys.exit(1)
    else:
        print(sql)
        print()
        print("="*60)
        print("Copy the SQL above to your Supabase SQL Editor and run it.")
        print("="*60)


if __name__ == "__main__":
    main()
